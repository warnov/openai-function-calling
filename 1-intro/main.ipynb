{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import random\n",
    "from openai.types.chat import ChatCompletionMessage, ChatCompletionMessageToolCall\n",
    "from openai import AzureOpenAI\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External Services Simulation\n",
    "This could be replaced with any backend, api, integration service, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    if \"bogota\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Bogota\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "    \n",
    "def get_n_day_weather_forecast(location, unit=\"fahrenheit\", num_days=3):\n",
    "    current_date = datetime.date.today()\n",
    "    forecast = []\n",
    "    \n",
    "    for i in range(num_days):\n",
    "        date = current_date + datetime.timedelta(days=i)\n",
    "        temperature = random.randint(10, 20)\n",
    "        forecast.append(f\"{date.strftime('%B %d')}: {temperature}\")\n",
    "    \n",
    "    return json.dumps({\"location\": location, \"forecast\": forecast, \"unit\": unit})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to visualize responses from LLM about what function and parameters should be called"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_chat_completion_message(chat_message: ChatCompletionMessage):\n",
    "    content = chat_message.content\n",
    "    print(\"Content:\")\n",
    "    print(json.dumps(content, indent=2))\n",
    "    \n",
    "    if chat_message.tool_calls:\n",
    "        for tool_call in chat_message.tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "            print(\"Function Name:\", function_name)\n",
    "            print(\"Arguments:\")\n",
    "            print(json.dumps(json.loads(arguments), indent=2))\n",
    "    else:\n",
    "        print(\"Functions: None\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure OpenAI client setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AI_ROADSHOW_AOAI_KEY\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AI_ROADSHOW_AOIA_ENDPOINT\")\n",
    ")\n",
    "deployment = \"ai-roadshow\" #gpt-3.5-turbo-0613\n",
    "messages = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to actually make the call to the function suggested by the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_caller(tool_calls: List[ChatCompletionMessageToolCall]):\n",
    "\n",
    "    if tool_calls:\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "            \"get_n_day_weather_forecast\": get_n_day_weather_forecast,\t\n",
    "        }  \n",
    "        \n",
    "        for tool_call in tool_calls:\n",
    "            function_name = tool_call.function.name\n",
    "            function_to_call = available_functions[function_name]\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            if function_name == \"get_current_weather\":\n",
    "                function_response = function_to_call(\n",
    "                    location=function_args.get(\"location\"),\n",
    "                    unit=function_args.get(\"unit\"))\n",
    "            elif function_name == \"get_n_day_weather_forecast\":\n",
    "                function_response = function_to_call(\n",
    "                    location=function_args.get(\"location\"),\n",
    "                    unit=function_args.get(\"unit\"),\n",
    "                    num_days=function_args.get(\"num_days\"))\n",
    "            \n",
    "            messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"role\": \"tool\",\n",
    "                    \"name\": function_name,\n",
    "                    \"content\": function_response,\n",
    "                }                \n",
    "            )           \n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=messages,\n",
    "    ).choices[0].message.content # get a new response from the model where it can see the function response\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model interaction method with retry policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(multiplier=1, max=40), stop=stop_after_attempt(3))\n",
    "def chat_completion_request(messages, tools=None, tool_choice=None, model=deployment):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=tool_choice,\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(\"Unable to generate ChatCompletion response\")\n",
    "        print(f\"Exception: {e}\")\n",
    "        return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of functions available for our aplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city for which to get the weather\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"fahrenheit\", \"celsius\"],\n",
    "                        \"description\": \"The temperature unit to use. Default is fahrenheit.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_n_day_weather_forecast\",\n",
    "            \"description\": \"Get an N-day weather forecast\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The location the user wants to know its weather\",\n",
    "                    },\n",
    "                    \"format\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                        \"description\": \"The temperature unit to use. Default is fahrenheit.\",\n",
    "                    },\n",
    "                    \"num_days\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"The number of days to forecast\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\", \"format\", \"num_days\"]\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing specifying location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "null\n",
      "Function Name: get_current_weather\n",
      "Arguments:\n",
      "{\n",
      "  \"location\": \"San Francisco\",\n",
      "  \"format\": \"fahrenheit\"\n",
      "}\n",
      "The current temperature in San Francisco is 72 degrees Fahrenheit.\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"I'm visiting San Francisco. What will be the weather today?\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "pretty_print_chat_completion_message(assistant_message)\n",
    "print(function_caller(assistant_message.tool_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing specifying the location and the preferred format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "null\n",
      "Function Name: get_current_weather\n",
      "Arguments:\n",
      "{\n",
      "  \"location\": \"Bogota\",\n",
      "  \"format\": \"celsius\"\n",
      "}\n",
      "The current temperature in Bogota is 10 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Please tell me the weather in Bogota, in celsius\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "pretty_print_chat_completion_message(assistant_message)\n",
    "print(function_caller(assistant_message.tool_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing without specifying location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "\"Sure! Could you please specify the location for which you want to know the weather?\"\n",
      "Functions: None\n",
      "I'm sorry, but I need the specific location for which you want the weather forecast. Can you please provide the city or town name?\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"How's going to be the weather?\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "pretty_print_chat_completion_message(assistant_message)\n",
    "print(function_caller(assistant_message.tool_calls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User answers the ask for location specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "null\n",
      "Function Name: get_current_weather\n",
      "Arguments:\n",
      "{\n",
      "  \"location\": \"Paris\",\n",
      "  \"format\": \"celsius\"\n",
      "}\n",
      "The current temperature in Paris is 22 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"I am in Paris\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "assistant_message\n",
    "pretty_print_chat_completion_message(assistant_message)\n",
    "print(function_caller(assistant_message.tool_calls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the other function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "null\n",
      "Function Name: get_n_day_weather_forecast\n",
      "Arguments:\n",
      "{\n",
      "  \"location\": \"Cartagena\",\n",
      "  \"format\": \"celsius\",\n",
      "  \"num_days\": 7\n",
      "}\n",
      "The weather in Cartagena for the next week will be as follows:\n",
      "- March 19: 13°C\n",
      "- March 20: 12°C\n",
      "- March 21: 10°C\n",
      "- March 22: 16°C\n",
      "- March 23: 11°C\n",
      "- March 24: 19°C\n",
      "- March 25: 18°C\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"How will be the weather in Cartagena for the next week?\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools\n",
    ")\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "pretty_print_chat_completion_message(assistant_message)\n",
    "print(function_caller(assistant_message.tool_calls))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Function Calling\n",
    "Newer models like gpt-4-1106-preview or gpt-3.5-turbo-1106 can call multiple functions in one turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content:\n",
      "null\n",
      "Function Name: get_n_day_weather_forecast\n",
      "Arguments:\n",
      "{\n",
      "  \"location\": \"San Francisco\",\n",
      "  \"format\": \"fahrenheit\",\n",
      "  \"num_days\": 4\n",
      "}\n",
      "Function Name: get_n_day_weather_forecast\n",
      "Arguments:\n",
      "{\n",
      "  \"location\": \"Bogota\",\n",
      "  \"format\": \"celsius\",\n",
      "  \"num_days\": 4\n",
      "}\n",
      "The weather forecast for the next 4 days is as follows:\n",
      "- San Francisco: March 19: 20°F, March 20: 13°F, March 21: 15°F, March 22: 11°F\n",
      "- Bogota: March 19: 15°C, March 20: 15°C, March 21: 19°C, March 22: 10°C\n"
     ]
    }
   ],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"AI_ROADSHOW_AOAI_1106_KEY\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=os.getenv(\"AI_ROADSHOW_AOIA_1106_ENDPOINT\")\n",
    ")\n",
    "\n",
    "deployment = \"ai-roadshow-1106\" #gpt-3.5-turbo-1106 is available in WEST US among selected regions\n",
    "messages = []\n",
    "messages.append({\"role\": \"system\", \"content\": \"Don't make assumptions about what values to plug into functions. Ask for clarification if a user request is ambiguous.\"})\n",
    "messages.append({\"role\": \"user\", \"content\": \"what is the weather going to be like in San Francisco and Bogota over the next 4 days\"})\n",
    "chat_response = chat_completion_request(\n",
    "    messages, tools=tools, model=deployment\n",
    ")\n",
    "\n",
    "assistant_message = chat_response.choices[0].message\n",
    "messages.append(assistant_message)\n",
    "pretty_print_chat_completion_message(assistant_message)\n",
    "print(function_caller(assistant_message.tool_calls))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
